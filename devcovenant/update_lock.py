"""Refresh dependency lockfiles and license artifacts from metadata."""

from __future__ import annotations

import argparse
import hashlib
import importlib.util
import shutil
import subprocess
import sys
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Callable, Dict, Iterable, List, Sequence, Tuple

if __package__ in {None, ""}:  # pragma: no cover
    sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from devcovenant.core.execution import resolve_repo_root
from devcovenant.core.policies.dependency_license_sync import (
    dependency_license_sync,
)
from devcovenant.core.policy_descriptor import (
    load_policy_descriptor,
    resolve_script_location,
)
from devcovenant.core.repo_refresh import (
    build_metadata_context,
    metadata_value_list,
    resolve_policy_metadata_map,
)

POLICY_ID = "dependency-license-sync"


@dataclass(frozen=True)
class LockFilePieces:
    """Describe the body of a generated requirements.lock snapshot."""

    body: List[str]


@dataclass(frozen=True)
class LockHandlerResult:
    """Outcome from one lockfile refresh strategy."""

    lock_file: str
    changed: bool
    attempted: bool
    message: str


def _compute_file_hash(path: Path) -> str:
    """Return a stable hash digest for a file."""

    return hashlib.sha256(path.read_bytes()).hexdigest()


def _file_hash_or_missing(path: Path) -> str:
    """Return digest string, with placeholder when file is absent."""

    if not path.exists():
        return "__missing__"
    return _compute_file_hash(path)


def _ensure_tool(command_name: str) -> bool:
    """Return True when a command is available on PATH."""

    return shutil.which(command_name) is not None


def _run_command(repo_root: Path, args: Sequence[str]) -> None:
    """Run one lockfile command and raise on failure."""

    subprocess.run(
        list(args),
        cwd=repo_root,
        check=True,
        text=True,
        capture_output=True,
    )


def _run_and_detect_change(
    repo_root: Path, lock_path: Path, command: Sequence[str]
) -> bool:
    """Run command and return True when target lockfile changed."""

    before = _file_hash_or_missing(lock_path)
    _run_command(repo_root, command)
    after = _file_hash_or_missing(lock_path)
    return before != after


def _normalise_header(lines: Sequence[str]) -> List[str]:
    """Stabilise pip-compile banners across Python versions."""

    python_banner = "# This file is autogenerated by pip-compile"
    target = (
        "#    pip-compile --allow-unsafe --strip-extras --output-file="
        "requirements.lock requirements.in"
    )
    result = list(lines)
    for index, line in enumerate(result):
        if line.startswith("#    pip-compile "):
            result[index] = target
            break
    for index, line in enumerate(result):
        if line.startswith(
            "# This file is autogenerated by pip-compile with Python"
        ):
            result[index] = python_banner
            break
    return result


def _split_last_updated(lines: Iterable[str]) -> LockFilePieces:
    """Drop optional Last Updated banner from lockfile body."""

    collected = list(lines)
    if collected and collected[0].startswith("# Last Updated:"):
        return LockFilePieces(collected[1:])
    return LockFilePieces(collected)


def _compile_requirements_lock(
    repo_root: Path, requirements_in: Path
) -> LockFilePieces:
    """Generate normalised requirements.lock content without touching disk."""

    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_lock = Path(tmpdir) / "requirements.lock"
        _run_pip_compile(repo_root, requirements_in, tmp_lock)
        normalised = _normalise_header(tmp_lock.read_text().splitlines())
    return _split_last_updated(normalised)


def _run_pip_compile(
    repo_root: Path, requirements_in: Path, output_path: Path
) -> None:
    """Run pip-compile with the repository's canonical options."""

    if importlib.util.find_spec("piptools") is None:
        raise RuntimeError(
            "pip-tools is required for requirements.lock updates."
        )
    _run_command(
        repo_root,
        (
            sys.executable,
            "-m",
            "piptools",
            "compile",
            "--quiet",
            "--allow-unsafe",
            "--strip-extras",
            "--output-file",
            str(output_path),
            requirements_in.name,
        ),
    )


def _refresh_python_requirements_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh requirements.lock from requirements.in."""

    req_in = repo_root / "requirements.in"
    lock_path = repo_root / "requirements.lock"
    if not req_in.exists():
        return LockHandlerResult(
            "requirements.lock",
            changed=False,
            attempted=False,
            message="Skipped: requirements.in missing.",
        )

    previous = (
        _split_last_updated(lock_path.read_text().splitlines())
        if lock_path.exists()
        else LockFilePieces([])
    )
    compiled = _compile_requirements_lock(repo_root, req_in)
    if previous.body == compiled.body:
        return LockHandlerResult(
            "requirements.lock",
            changed=False,
            attempted=True,
            message="No content change after pip-compile.",
        )
    lock_path.write_text("\n".join(compiled.body) + "\n", encoding="utf-8")
    return LockHandlerResult(
        "requirements.lock",
        changed=True,
        attempted=True,
        message="Updated requirements.lock.",
    )


def _refresh_npm_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh package-lock.json from package.json."""

    package_json = repo_root / "package.json"
    lock_path = repo_root / "package-lock.json"
    if not package_json.exists():
        return LockHandlerResult(
            "package-lock.json",
            changed=False,
            attempted=False,
            message="Skipped: package.json missing.",
        )
    if not _ensure_tool("npm"):
        return LockHandlerResult(
            "package-lock.json",
            changed=False,
            attempted=False,
            message="Skipped: npm not installed.",
        )
    changed = _run_and_detect_change(
        repo_root,
        lock_path,
        ("npm", "install", "--package-lock-only"),
    )
    message = "Updated package-lock.json." if changed else "No change."
    return LockHandlerResult("package-lock.json", changed, True, message)


def _refresh_yarn_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh yarn.lock from package.json."""

    package_json = repo_root / "package.json"
    lock_path = repo_root / "yarn.lock"
    if not package_json.exists():
        return LockHandlerResult(
            "yarn.lock",
            changed=False,
            attempted=False,
            message="Skipped: package.json missing.",
        )
    if not _ensure_tool("yarn"):
        return LockHandlerResult(
            "yarn.lock",
            changed=False,
            attempted=False,
            message="Skipped: yarn not installed.",
        )
    changed = _run_and_detect_change(
        repo_root,
        lock_path,
        ("yarn", "install", "--mode=update-lockfile"),
    )
    message = "Updated yarn.lock." if changed else "No change."
    return LockHandlerResult("yarn.lock", changed, True, message)


def _refresh_pnpm_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh pnpm-lock.yaml from package.json."""

    package_json = repo_root / "package.json"
    lock_path = repo_root / "pnpm-lock.yaml"
    if not package_json.exists():
        return LockHandlerResult(
            "pnpm-lock.yaml",
            changed=False,
            attempted=False,
            message="Skipped: package.json missing.",
        )
    if not _ensure_tool("pnpm"):
        return LockHandlerResult(
            "pnpm-lock.yaml",
            changed=False,
            attempted=False,
            message="Skipped: pnpm not installed.",
        )
    changed = _run_and_detect_change(
        repo_root,
        lock_path,
        ("pnpm", "install", "--lockfile-only"),
    )
    message = "Updated pnpm-lock.yaml." if changed else "No change."
    return LockHandlerResult("pnpm-lock.yaml", changed, True, message)


def _refresh_go_sum(repo_root: Path) -> LockHandlerResult:
    """Refresh go.sum from go.mod."""

    go_mod = repo_root / "go.mod"
    lock_path = repo_root / "go.sum"
    if not go_mod.exists():
        return LockHandlerResult(
            "go.sum",
            changed=False,
            attempted=False,
            message="Skipped: go.mod missing.",
        )
    if not _ensure_tool("go"):
        return LockHandlerResult(
            "go.sum",
            changed=False,
            attempted=False,
            message="Skipped: go not installed.",
        )
    changed = _run_and_detect_change(
        repo_root, lock_path, ("go", "mod", "tidy")
    )
    message = "Updated go.sum." if changed else "No change."
    return LockHandlerResult("go.sum", changed, True, message)


def _refresh_cargo_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh Cargo.lock from Cargo.toml."""

    cargo_toml = repo_root / "Cargo.toml"
    lock_path = repo_root / "Cargo.lock"
    if not cargo_toml.exists():
        return LockHandlerResult(
            "Cargo.lock",
            changed=False,
            attempted=False,
            message="Skipped: Cargo.toml missing.",
        )
    if not _ensure_tool("cargo"):
        return LockHandlerResult(
            "Cargo.lock",
            changed=False,
            attempted=False,
            message="Skipped: cargo not installed.",
        )
    changed = _run_and_detect_change(
        repo_root, lock_path, ("cargo", "generate-lockfile")
    )
    message = "Updated Cargo.lock." if changed else "No change."
    return LockHandlerResult("Cargo.lock", changed, True, message)


def _refresh_composer_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh composer.lock from composer.json."""

    composer_json = repo_root / "composer.json"
    lock_path = repo_root / "composer.lock"
    if not composer_json.exists():
        return LockHandlerResult(
            "composer.lock",
            changed=False,
            attempted=False,
            message="Skipped: composer.json missing.",
        )
    if not _ensure_tool("composer"):
        return LockHandlerResult(
            "composer.lock",
            changed=False,
            attempted=False,
            message="Skipped: composer not installed.",
        )
    changed = _run_and_detect_change(
        repo_root,
        lock_path,
        ("composer", "update", "--lock", "--no-install"),
    )
    message = "Updated composer.lock." if changed else "No change."
    return LockHandlerResult("composer.lock", changed, True, message)


def _refresh_gemfile_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh Gemfile.lock from Gemfile."""

    gemfile = repo_root / "Gemfile"
    lock_path = repo_root / "Gemfile.lock"
    if not gemfile.exists():
        return LockHandlerResult(
            "Gemfile.lock",
            changed=False,
            attempted=False,
            message="Skipped: Gemfile missing.",
        )
    if not _ensure_tool("bundle"):
        return LockHandlerResult(
            "Gemfile.lock",
            changed=False,
            attempted=False,
            message="Skipped: bundler not installed.",
        )
    changed = _run_and_detect_change(repo_root, lock_path, ("bundle", "lock"))
    message = "Updated Gemfile.lock." if changed else "No change."
    return LockHandlerResult("Gemfile.lock", changed, True, message)


def _refresh_pubspec_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh pubspec.lock from pubspec.yaml."""

    pubspec = repo_root / "pubspec.yaml"
    lock_path = repo_root / "pubspec.lock"
    if not pubspec.exists():
        return LockHandlerResult(
            "pubspec.lock",
            changed=False,
            attempted=False,
            message="Skipped: pubspec.yaml missing.",
        )
    if _ensure_tool("flutter"):
        changed = _run_and_detect_change(
            repo_root, lock_path, ("flutter", "pub", "get")
        )
        message = (
            "Updated pubspec.lock via flutter." if changed else "No change."
        )
        return LockHandlerResult("pubspec.lock", changed, True, message)
    if _ensure_tool("dart"):
        changed = _run_and_detect_change(
            repo_root, lock_path, ("dart", "pub", "get")
        )
        message = "Updated pubspec.lock via dart." if changed else "No change."
        return LockHandlerResult("pubspec.lock", changed, True, message)
    return LockHandlerResult(
        "pubspec.lock",
        changed=False,
        attempted=False,
        message="Skipped: neither flutter nor dart is installed.",
    )


def _refresh_podfile_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh Podfile.lock from Podfile."""

    podfile = repo_root / "Podfile"
    lock_path = repo_root / "Podfile.lock"
    if not podfile.exists():
        return LockHandlerResult(
            "Podfile.lock",
            changed=False,
            attempted=False,
            message="Skipped: Podfile missing.",
        )
    if not _ensure_tool("pod"):
        return LockHandlerResult(
            "Podfile.lock",
            changed=False,
            attempted=False,
            message="Skipped: cocoapods is not installed.",
        )
    changed = _run_and_detect_change(
        repo_root,
        lock_path,
        ("pod", "install", "--no-repo-update"),
    )
    message = "Updated Podfile.lock." if changed else "No change."
    return LockHandlerResult("Podfile.lock", changed, True, message)


def _refresh_dotnet_lock(repo_root: Path) -> LockHandlerResult:
    """Refresh packages.lock.json when .NET projects are present."""

    lock_path = repo_root / "packages.lock.json"
    csproj_files = list(repo_root.glob("*.csproj"))
    if not csproj_files:
        return LockHandlerResult(
            "packages.lock.json",
            changed=False,
            attempted=False,
            message="Skipped: no top-level *.csproj file found.",
        )
    if not _ensure_tool("dotnet"):
        return LockHandlerResult(
            "packages.lock.json",
            changed=False,
            attempted=False,
            message="Skipped: dotnet not installed.",
        )
    changed = _run_and_detect_change(
        repo_root,
        lock_path,
        ("dotnet", "restore", "--use-lock-file"),
    )
    message = "Updated packages.lock.json." if changed else "No change."
    return LockHandlerResult("packages.lock.json", changed, True, message)


LOCKFILE_HANDLERS: Dict[str, Callable[[Path], LockHandlerResult]] = {
    "requirements.lock": _refresh_python_requirements_lock,
    "package-lock.json": _refresh_npm_lock,
    "yarn.lock": _refresh_yarn_lock,
    "pnpm-lock.yaml": _refresh_pnpm_lock,
    "go.sum": _refresh_go_sum,
    "Cargo.lock": _refresh_cargo_lock,
    "composer.lock": _refresh_composer_lock,
    "Gemfile.lock": _refresh_gemfile_lock,
    "pubspec.lock": _refresh_pubspec_lock,
    "Podfile.lock": _refresh_podfile_lock,
    "packages.lock.json": _refresh_dotnet_lock,
}


def _csv_to_list(raw_value: str) -> List[str]:
    """Expand a comma-separated metadata string into a clean list."""

    items = []
    for token in str(raw_value or "").split(","):
        cleaned = token.strip()
        if cleaned and cleaned != "__none__":
            items.append(cleaned)
    return items


def _descriptor_metadata_lists(
    repo_root: Path,
    policy_id: str,
) -> Tuple[List[str], Dict[str, List[str]]]:
    """Load descriptor defaults into order/list map representation."""

    descriptor = load_policy_descriptor(repo_root, policy_id)
    if descriptor is None:
        return [], {}
    order: List[str] = []
    values: Dict[str, List[str]] = {}
    for key, raw_value in descriptor.metadata.items():
        key_name = str(key).strip()
        if not key_name:
            continue
        order.append(key_name)
        values[key_name] = metadata_value_list(raw_value)
    return order, values


def _resolve_dependency_metadata(repo_root: Path) -> Dict[str, object]:
    """Resolve dependency-license-sync metadata from profiles and config."""

    order, values = _descriptor_metadata_lists(repo_root, POLICY_ID)
    descriptor = load_policy_descriptor(repo_root, POLICY_ID)
    context = build_metadata_context(repo_root)
    location = resolve_script_location(repo_root, POLICY_ID)
    core_available = (
        repo_root
        / "devcovenant"
        / "core"
        / "policies"
        / "dependency_license_sync"
        / "dependency_license_sync.py"
    ).exists()
    custom_policy = bool(location and location.kind == "custom")
    _, resolved = resolve_policy_metadata_map(
        POLICY_ID,
        order,
        values,
        descriptor,
        context,
        core_available=core_available,
        custom_policy=custom_policy,
    )
    dependency_files = _csv_to_list(resolved.get("dependency_files", ""))
    return {
        "dependency_files": dependency_files,
        "third_party_file": str(
            resolved.get(
                "third_party_file",
                str(dependency_license_sync.THIRD_PARTY),
            )
        ).strip(),
        "licenses_dir": str(
            resolved.get(
                "licenses_dir",
                dependency_license_sync.LICENSES_DIR,
            )
        ).strip(),
        "report_heading": str(
            resolved.get(
                "report_heading",
                dependency_license_sync.LICENSE_REPORT_HEADING,
            )
        ).strip(),
    }


def refresh_locks_and_licenses(
    repo_root: Path,
) -> Tuple[List[LockHandlerResult], List[Path]]:
    """Refresh selected lockfiles and policy-owned license artifacts."""

    metadata = _resolve_dependency_metadata(repo_root)
    dependency_files = set(metadata["dependency_files"])
    targets = [
        lock_name
        for lock_name in LOCKFILE_HANDLERS
        if lock_name in dependency_files
    ]
    results: List[LockHandlerResult] = []
    changed_lockfiles: List[str] = []
    for lock_name in targets:
        handler = LOCKFILE_HANDLERS[lock_name]
        try:
            result = handler(repo_root)
        except subprocess.CalledProcessError as exc:
            message = (
                f"Failed while running {' '.join(exc.cmd)} "
                f"(exit {exc.returncode})."
            )
            result = LockHandlerResult(lock_name, False, True, message)
        results.append(result)
        if result.changed:
            changed_lockfiles.append(lock_name)

    modified_license_files: List[Path] = []
    if changed_lockfiles:
        modified_license_files = (
            dependency_license_sync.refresh_license_artifacts(
                repo_root,
                changed_dependency_files=changed_lockfiles,
                third_party_file=str(metadata["third_party_file"]),
                licenses_dir=str(metadata["licenses_dir"]),
                report_heading=str(metadata["report_heading"]),
            )
        )
    return results, modified_license_files


def _build_parser() -> argparse.ArgumentParser:
    """Build parser for update_lock command."""

    parser = argparse.ArgumentParser(
        description=(
            "Refresh dependency lockfiles for active profiles and keep "
            "license artifacts in sync."
        )
    )
    return parser


def run(args: argparse.Namespace) -> int:
    """Execute the update_lock command."""

    del args
    repo_root = resolve_repo_root(require_install=True)
    results, license_files = refresh_locks_and_licenses(repo_root)
    if not results:
        print(
            "No metadata-selected lockfiles are configured for this repo.",
            file=sys.stdout,
        )
        return 0

    changed = [entry for entry in results if entry.changed]
    attempted = [entry for entry in results if entry.attempted]
    skipped = [entry for entry in results if not entry.attempted]

    print("Lock refresh results:", file=sys.stdout)
    for entry in results:
        print(f"- {entry.lock_file}: {entry.message}", file=sys.stdout)

    if changed:
        changed_names = ", ".join(entry.lock_file for entry in changed)
        print(f"Updated lockfiles: {changed_names}", file=sys.stdout)
    else:
        print("No lockfile content changed.", file=sys.stdout)

    if license_files:
        refreshed = ", ".join(str(path) for path in license_files)
        print(f"Refreshed license artifacts: {refreshed}", file=sys.stdout)

    if not attempted and skipped:
        print(
            "All handlers skipped due missing prerequisites/tools.",
            file=sys.stdout,
        )
    return 0


def main(argv: Sequence[str] | None = None) -> None:
    """CLI entry point."""

    parser = _build_parser()
    args = parser.parse_args(argv)
    raise SystemExit(run(args))


if __name__ == "__main__":
    main()
