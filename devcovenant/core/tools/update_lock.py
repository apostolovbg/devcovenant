"""Generate deterministic lockfiles without churning metadata.

This helper wraps :mod:`piptools` so the ``make lock`` target only rewrites
``requirements.lock`` when dependency contents change. The previous
workflow bumped a ``Last Updated`` banner on every run, forcing noisy diffs
even when the dependency graph stayed identical. The banner is now removed
to align with the restricted metadata allowlist while keeping the compiled
body stable across Python versions.
"""

from __future__ import annotations

import argparse
import hashlib
import importlib.util
import subprocess
import sys
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List, Sequence

ROOT = Path(__file__).resolve().parents[1]


@dataclass(frozen=True)
class LockFilePieces:
    """Describe the pieces of a ``requirements.lock`` snapshot."""

    body: List[str]


def _cache_dir(root: Path) -> Path:
    """Return the location used for transient cache metadata."""

    return root / ".cache"


def _input_hash_path(root: Path) -> Path:
    """Return the cached hash path for ``requirements.in``."""

    return _cache_dir(root) / "requirements.in.hash"


def _ensure_cache_dir(root: Path) -> None:
    """Create the cache directory if it is missing."""

    _cache_dir(root).mkdir(parents=True, exist_ok=True)


def _read_cached_input_hash(root: Path) -> str | None:
    """Return the stored hash for ``requirements.in`` if available."""

    path = _input_hash_path(root)
    if not path.exists():
        return None
    return path.read_text(encoding="utf-8").strip()


def _write_cached_input_hash(root: Path, hash_digest: str) -> None:
    """Persist the current ``requirements.in`` hash for future runs."""

    _ensure_cache_dir(root)
    _input_hash_path(root).write_text(hash_digest, encoding="utf-8")


def _compute_requirements_hash(path: Path) -> str:
    """Return a stable digest for the input requirements."""

    return hashlib.sha256(path.read_bytes()).hexdigest()


def ensure_piptools_available() -> None:
    """Abort with guidance when :mod:`piptools` is unavailable."""

    # ``pip-compile`` ships inside the ``piptools`` package.  Import discovery
    # keeps the helper safe to import even when the optional dependency is
    # absent, so the unit tests can monkeypatch ``run_pip_compile`` without
    # tripping the process-wide ``SystemExit`` that previously fired at module
    # import time.
    if importlib.util.find_spec("piptools") is None:
        raise SystemExit(
            "pip-tools is required to regenerate requirements.lock. Install "
            "the repository's pinned version with `python -m pip install "
            "pip-tools==7.4.1`."
        )


def ensure_inputs(root: Path) -> tuple[Path, Path]:
    """Return the ``requirements`` inputs and ensure they exist."""

    req_in = root / "requirements.in"
    lock_path = root / "requirements.lock"
    if not req_in.exists():
        raise SystemExit(
            "requirements.in is missing; run the helper from the repository "
            "root or provide --root with a valid project directory."
        )
    return req_in, lock_path


def run_pip_compile(
    root: Path, requirements_in: Path, output_path: Path
) -> None:
    """Invoke ``pip-compile`` with the repository's canonical flags."""

    ensure_piptools_available()
    subprocess.run(
        [
            sys.executable,
            "-m",
            "piptools",
            "compile",
            "--quiet",
            "--allow-unsafe",
            "--strip-extras",
            "--output-file",
            str(output_path),
            requirements_in.name,
        ],
        cwd=root,
        check=True,
    )


def normalise_header(lines: Sequence[str]) -> List[str]:
    """Stabilise ``pip-compile`` banners across Python versions."""

    python_banner = "# This file is autogenerated by pip-compile"
    target = (
        "#    pip-compile --allow-unsafe --strip-extras --output-file="
        "requirements.lock requirements.in"
    )
    result = list(lines)
    for index, line in enumerate(result):
        if line.startswith("#    pip-compile "):
            result[index] = target
            break
    for index, line in enumerate(result):
        if line.startswith(
            "# This file is autogenerated by pip-compile with Python"
        ):
            result[index] = python_banner
            break
    return result


def split_last_updated(lines: Iterable[str]) -> LockFilePieces:
    """Separate the optional ``Last Updated`` banner from the body."""

    collected = list(lines)
    if collected and collected[0].startswith("# Last Updated:"):
        return LockFilePieces(collected[1:])
    return LockFilePieces(collected)


def compile_new_lock(root: Path, requirements_in: Path) -> LockFilePieces:
    """Generate a normalised lockfile snapshot without touching disk."""

    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_lock = Path(tmpdir) / "requirements.lock"
        run_pip_compile(root, requirements_in, tmp_lock)
        normalised = normalise_header(tmp_lock.read_text().splitlines())
    return split_last_updated(normalised)


def read_existing_lock(lock_path: Path) -> LockFilePieces:
    """Return the current ``requirements.lock`` pieces, if any."""

    if not lock_path.exists():
        return LockFilePieces([])
    return split_last_updated(lock_path.read_text().splitlines())


def write_lock(lock_path: Path, body: Sequence[str]) -> None:
    """Persist the reconstructed lockfile without metadata banners."""

    lock_path.write_text("\n".join(body) + "\n", encoding="utf-8")


def update_lockfile(root: Path, force: bool = False) -> bool:
    """Refresh ``requirements.lock`` and return ``True`` when it changed."""

    requirements_in, lock_path = ensure_inputs(root)
    previous = read_existing_lock(lock_path)
    current_hash = _compute_requirements_hash(requirements_in)
    cached_hash = _read_cached_input_hash(root)
    if not force and cached_hash == current_hash and lock_path.exists():
        return False
    compiled = compile_new_lock(root, requirements_in)
    _write_cached_input_hash(root, current_hash)
    if previous.body == compiled.body:
        return False
    write_lock(lock_path, compiled.body)
    return True


def parse_args() -> argparse.Namespace:
    """Return command-line arguments for the helper."""

    parser = argparse.ArgumentParser(
        description=(
            "Regenerate requirements.lock without reintroducing metadata "
            "banners when the dependency body is unchanged."
        )
    )
    parser.add_argument(
        "--root",
        type=Path,
        default=ROOT,
        help=(
            "Project root containing requirements.in and requirements.lock. "
            "Defaults to the repository root inferred from this script."
        ),
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help=(
            "Force regeneration even if the requirements input hash "
            "did not change."
        ),
    )
    return parser.parse_args()


def main() -> None:
    """Entry-point for the command-line interface."""

    args = parse_args()
    changed = update_lockfile(args.root, force=args.force)
    if changed:
        print("requirements.lock updated", file=sys.stdout)
    else:
        print("requirements.lock already up to date", file=sys.stdout)


if __name__ == "__main__":
    main()
